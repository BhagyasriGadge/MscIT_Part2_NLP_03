{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Prac2E.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjsmrdahuI_C",
        "outputId": "17403e0f-81c7-47a4-d22b-61df5df1a16e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[('Nick', 'NNP'), ('likes', 'VBZ'), ('to', 'TO'), ('play', 'VB'), ('football', 'NN'), ('.', '.'), ('Nick', 'NNP'), ('does', 'VBZ'), ('not', 'RB'), ('like', 'VB'), ('to', 'TO'), ('play', 'VB'), ('cricket', 'NN'), ('.', '.')]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from collections import defaultdict\n",
        "text = nltk.word_tokenize(\"Nick likes to play football. Nick does not like to play cricket.\")\n",
        "tagged = nltk.pos_tag(text)\n",
        "print(tagged)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# checking if it is a noun or not\n",
        "addNounWords = []\n",
        "count=0\n",
        "for words in tagged:\n",
        "  val = tagged[count][1]\n",
        "  if(val == 'NN' or val == 'NNS' or val == 'NNPS' or val == 'NNP'):\n",
        "    addNounWords.append(tagged[count][0])\n",
        "    count+=1\n",
        "    print (addNounWords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MusQoRXEuT17",
        "outputId": "9b98b22c-0476-4b8e-8bec-62512a0dfb07"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Nick']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = defaultdict(int)\n",
        "# memoizing count\n",
        "for sub in addNounWords:\n",
        "  for wrd in sub.split():\n",
        "    temp[wrd] += 1"
      ],
      "metadata": {
        "id": "TcRHxfRlu9sT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # getting max frequency\n",
        "res = max(temp, key=temp.get)\n",
        "# printing result\n",
        "print(\"Word with maximum frequency : \" + str(res))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5IMfVPGvGVk",
        "outputId": "a7c711a7-9400-4363-9a0a-d435b6df1e6b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word with maximum frequency : Nick\n"
          ]
        }
      ]
    }
  ]
}