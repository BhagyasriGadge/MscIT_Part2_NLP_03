{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Prac1010.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqGxDrGKerka",
        "outputId": "292a3caa-f6ab-4a89-dd2d-9fdd8434b6fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I like to play football. I hated it in my childhood though\n",
            "VERB\n",
            "VBD\n",
            "verb, past tense\n",
            "I            PRON       PRP      pronoun, personal\n",
            "like         VERB       VBP      verb, non-3rd person singular present\n",
            "to           PART       TO       infinitival \"to\"\n",
            "play         VERB       VB       verb, base form\n",
            "football     NOUN       NN       noun, singular or mass\n",
            ".            PUNCT      .        punctuation mark, sentence closer\n",
            "I            PRON       PRP      pronoun, personal\n",
            "hated        VERB       VBD      verb, past tense\n",
            "it           PRON       PRP      pronoun, personal\n",
            "in           ADP        IN       conjunction, subordinating or preposition\n",
            "my           DET        PRP$     pronoun, possessive\n",
            "childhood    NOUN       NN       noun, singular or mass\n",
            "though       SCONJ      IN       conjunction, subordinating or preposition\n"
          ]
        }
      ],
      "source": [
        "#a. Speech Tagging:\n",
        "#i. Speech tagging using spacy\n",
        "import spacy\n",
        "sp = spacy.load('en_core_web_sm')\n",
        "sen = sp(u\"I like to play football. I hated it in my childhood though\")\n",
        "print(sen.text)\n",
        "print(sen[7].pos_)\n",
        "print(sen[7].tag_)\n",
        "print(spacy.explain(sen[7].tag_))\n",
        "for word in sen:\n",
        "  print(f'{word.text:{12}} {word.pos_:{10}} {word.tag_:{8}} {spacy.explain(word.tag_)}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sen = sp(u'Can you google it?')\n",
        "word = sen[2]\n",
        "print(f'{word.text:{12}} {word.pos_:{10}} {word.tag_:{8}} {spacy.explain(word.tag_)}')\n",
        "sen = sp(u'Can you search it on google?')\n",
        "word = sen[5]\n",
        "print(f'{word.text:{12}} {word.pos_:{10}} {word.tag_:{8}} {spacy.explain(word.tag_)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCFJ2-chfzYB",
        "outputId": "b2ca8b8a-3313-4d6a-a148-8668c137c4db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "google       VERB       VB       verb, base form\n",
            "google       PROPN      NNP      noun, proper singular\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finding the Number of POS Tags\n",
        "sen = sp(u\"I like to play football. I hated it in my childhood though\")\n",
        "num_pos = sen.count_by(spacy.attrs.POS)\n",
        "num_pos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIAT4K70f1KO",
        "outputId": "048bfdb8-8803-4a54-e320-0465ac5e4965"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{85: 1, 90: 1, 92: 2, 94: 1, 95: 3, 97: 1, 98: 1, 100: 3}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k,v in sorted(num_pos.items()):\n",
        "  print(f'{k}. {sen.vocab[k].text:{8}}: {v}')\n",
        "  \n",
        "#Visualizing Parts of Speech Tags\n",
        "from spacy import displacy\n",
        "sen = sp(u\"I like to play football. I hated it in my childhood though\")\n",
        "displacy.serve(sen, style='dep', options={'distance': 120})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TLkBtmLf8ZJ",
        "outputId": "bcf4b8b9-77d9-446a-8a62-f2ee42f4b62f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "85. ADP     : 1\n",
            "90. DET     : 1\n",
            "92. NOUN    : 2\n",
            "94. PART    : 1\n",
            "95. PRON    : 3\n",
            "97. PUNCT   : 1\n",
            "98. SCONJ   : 1\n",
            "100. VERB    : 3\n",
            "\n",
            "Using the 'dep' visualizer\n",
            "Serving on http://0.0.0.0:5000 ...\n",
            "\n",
            "Shutting down server on port 5000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ii. Speech tagging using nktl\n",
        "nltk.download('state_union')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import nltk\n",
        "from nltk.corpus import state_union\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "#create our training and testing data:\n",
        "train_text = state_union.raw(\"2005-GWBush.txt\")\n",
        "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
        "#train the Punkt tokenizer like:\n",
        "custom_sent_tokenizer = PunktSentenceTokenizer(train_text)\n",
        "# tokenize:\n",
        "tokenized = custom_sent_tokenizer.tokenize(sample_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0i222xqghyg",
        "outputId": "9ae2b3c2-f79a-4a61-a72a-86cdf9278bdf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]   Package state_union is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_content():\n",
        "  try:\n",
        "    for i in tokenized[:2]:\n",
        "      words = nltk.word_tokenize(i)\n",
        "      tagged = nltk.pos_tag(words)\n",
        "      print(tagged)\n",
        "  except Exception as e:\n",
        "    print(str(e))"
      ],
      "metadata": {
        "id": "vAi37IWcik3n"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_content()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1uqyBWqi5gE",
        "outputId": "8e53e182-8585-4cad-99f4-b3a6e35f76e6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('PRESIDENT', 'NNP'), ('GEORGE', 'NNP'), ('W.', 'NNP'), ('BUSH', 'NNP'), (\"'S\", 'POS'), ('ADDRESS', 'NNP'), ('BEFORE', 'IN'), ('A', 'NNP'), ('JOINT', 'NNP'), ('SESSION', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('CONGRESS', 'NNP'), ('ON', 'NNP'), ('THE', 'NNP'), ('STATE', 'NNP'), ('OF', 'IN'), ('THE', 'NNP'), ('UNION', 'NNP'), ('January', 'NNP'), ('31', 'CD'), (',', ','), ('2006', 'CD'), ('THE', 'NNP'), ('PRESIDENT', 'NNP'), (':', ':'), ('Thank', 'NNP'), ('you', 'PRP'), ('all', 'DT'), ('.', '.')]\n",
            "[('Mr.', 'NNP'), ('Speaker', 'NNP'), (',', ','), ('Vice', 'NNP'), ('President', 'NNP'), ('Cheney', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('Congress', 'NNP'), (',', ','), ('members', 'NNS'), ('of', 'IN'), ('the', 'DT'), ('Supreme', 'NNP'), ('Court', 'NNP'), ('and', 'CC'), ('diplomatic', 'JJ'), ('corps', 'NN'), (',', ','), ('distinguished', 'JJ'), ('guests', 'NNS'), (',', ','), ('and', 'CC'), ('fellow', 'JJ'), ('citizens', 'NNS'), (':', ':'), ('Today', 'VB'), ('our', 'PRP$'), ('nation', 'NN'), ('lost', 'VBD'), ('a', 'DT'), ('beloved', 'VBN'), (',', ','), ('graceful', 'JJ'), (',', ','), ('courageous', 'JJ'), ('woman', 'NN'), ('who', 'WP'), ('called', 'VBD'), ('America', 'NNP'), ('to', 'TO'), ('its', 'PRP$'), ('founding', 'NN'), ('ideals', 'NNS'), ('and', 'CC'), ('carried', 'VBD'), ('on', 'IN'), ('a', 'DT'), ('noble', 'JJ'), ('dream', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#b. Statistical parsing:\n",
        "#i. Usage of Give and Gave in the Penn Treebank sample\n",
        "import nltk\n",
        "import nltk.parse.viterbi\n",
        "import nltk.parse.pchart\n",
        "def give(t):\n",
        "  return t.label() == 'VP' and len(t) > 2 and t[1].label() == 'NP'\\\n",
        "  and (t[2].label() == 'PP-DTV' or t[2].label() == 'NP')\\\n",
        "  and ('give' in t[0].leaves() or 'gave' in t[0].leaves())"
      ],
      "metadata": {
        "id": "cHWQFc69jZvo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sent(t):\n",
        "  return ' '.join(token for token in t.leaves() if token[0] not in '*-0')"
      ],
      "metadata": {
        "id": "6GOUZ8Q_jlp-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_node(t, width):\n",
        "  output = \"%s %s: %s / %s: %s\" %\\\n",
        "  (sent(t[0]), t[1].label(), sent(t[1]), t[2].label(), sent(t[2]))\n",
        "  if len(output) > width:\n",
        "    output = output[:width] + \"...\"\n",
        "  print (output)"
      ],
      "metadata": {
        "id": "8oJIXFoGjo8G"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('treebank')\n",
        "for tree in nltk.corpus.treebank.parsed_sents():\n",
        "  for t in tree.subtrees(give):\n",
        "    print_node(t, 72)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNxZvncNjvil",
        "outputId": "90a08b5a-be4a-49c6-d5b8-06d5b86ae712"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/treebank.zip.\n",
            "gave NP: the chefs / NP: a standing ovation\n",
            "give NP: advertisers / NP: discounts for maintaining or increasing ad sp...\n",
            "give NP: it / PP-DTV: to the politicians\n",
            "gave NP: them / NP: similar help\n",
            "give NP: them / NP: \n",
            "give NP: only French history questions / PP-DTV: to students in a Europe...\n",
            "give NP: federal judges / NP: a raise\n",
            "give NP: consumers / NP: the straight scoop on the U.S. waste crisis\n",
            "gave NP: Mitsui / NP: access to a high-tech medical product\n",
            "give NP: Mitsubishi / NP: a window on the U.S. glass industry\n",
            "give NP: much thought / PP-DTV: to the rates she was receiving , nor to ...\n",
            "give NP: your Foster Savings Institution / NP: the gift of hope and free...\n",
            "give NP: market operators / NP: the authority to suspend trading in futu...\n",
            "gave NP: quick approval / PP-DTV: to $ 3.18 billion in supplemental appr...\n",
            "give NP: the Transportation Department / NP: up to 50 days to review any...\n",
            "give NP: the president / NP: such power\n",
            "give NP: me / NP: the heebie-jeebies\n",
            "give NP: holders / NP: the right , but not the obligation , to buy a cal...\n",
            "gave NP: Mr. Thomas / NP: only a `` qualified '' rating , rather than ``...\n",
            "give NP: the president / NP: line-item veto power\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ii. probabilistic parser\n",
        "import nltk\n",
        "from nltk import PCFG\n",
        "grammar = PCFG.fromstring('''\n",
        "NP -> NNS [0.5] | JJ NNS [0.3] | NP CC NP [0.2]\n",
        "NNS -> \"men\" [0.1] | \"women\" [0.2] | \"children\" [0.3] | NNS CC NNS [0.4]\n",
        "JJ -> \"old\" [0.4] | \"young\" [0.6]\n",
        "CC -> \"and\" [0.9] | \"or\" [0.1]\n",
        "''')\n",
        "print(grammar)\n",
        "viterbi_parser = nltk.ViterbiParser(grammar)\n",
        "token = \"old men and women\".split()\n",
        "obj = viterbi_parser.parse(token)\n",
        "print(\"Output: \")\n",
        "for x in obj:\n",
        "  print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwRGNFLTkB04",
        "outputId": "2974ddb9-2af3-4932-e04b-8eb448739e9e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grammar with 11 productions (start state = NP)\n",
            "    NP -> NNS [0.5]\n",
            "    NP -> JJ NNS [0.3]\n",
            "    NP -> NP CC NP [0.2]\n",
            "    NNS -> 'men' [0.1]\n",
            "    NNS -> 'women' [0.2]\n",
            "    NNS -> 'children' [0.3]\n",
            "    NNS -> NNS CC NNS [0.4]\n",
            "    JJ -> 'old' [0.4]\n",
            "    JJ -> 'young' [0.6]\n",
            "    CC -> 'and' [0.9]\n",
            "    CC -> 'or' [0.1]\n",
            "Output: \n",
            "(NP (JJ old) (NNS (NNS men) (CC and) (NNS women))) (p=0.000864)\n"
          ]
        }
      ]
    }
  ]
}